{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3367a196",
   "metadata": {},
   "source": [
    "**Going to practice with motor data set from mne dataset example at *mne.datasets.fnirs_motor.data_path()***\n",
    "\n",
    "This dataset contains a single subject recorded at Macquarie University. It has optodes placed over the motor cortex. \n",
    "\n",
    "**There are three conditions:**\n",
    "\n",
    "1. tapping the left thumb to fingers\n",
    "\n",
    "2. tapping the right thumb to fingers\n",
    "\n",
    "3. a control where nothing happens\n",
    "\n",
    "The tapping lasts 5 seconds, and there are 30 trials of each condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f6b4e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import compress\n",
    "from numpy.testing import assert_allclose\n",
    "\n",
    "import mne\n",
    "import pysnirf2\n",
    "\n",
    "MODULE_PATH = op.join(os.getcwd(), 'mne_nirs\\\\__init__.py')\n",
    "MODULE_NAME = 'mne_nirs'\n",
    "\n",
    "import importlib\n",
    "import sys\n",
    "spec = importlib.util.spec_from_file_location(MODULE_NAME, MODULE_PATH)\n",
    "module = importlib.util.module_from_spec(spec)\n",
    "sys.modules[spec.name] = module \n",
    "spec.loader.exec_module(module)\n",
    "\n",
    "\n",
    "\n",
    "from mne.io import read_raw_nirx, read_raw_snirf\n",
    "from mne_nirs.io import write_raw_snirf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23abc3ca",
   "metadata": {},
   "source": [
    "NIRS can be performed using methods in continuous wave (CW) (constant illumination), time domain (TD) (pulsed illumination and time-resolved detection), or frequency domain (FD) (intensity-modulated illumination and phase-resolved detection). CW techniques are the most common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a89713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taubm\\mne_data\\MNE-fNIRS-motor-data\n",
      "Loading C:\\Users\\taubm\\mne_data\\MNE-fNIRS-motor-data\\Participant-1\n",
      "Reading 0 ... 23238  =      0.000 ...  2974.464 secs...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Get path to local copy of fnirs_motor dataset\n",
    "fnirs_data_folder = mne.datasets.fnirs_motor.data_path()\n",
    "print(fnirs_data_folder)\n",
    "\n",
    "#returns path to file with data for 1st participant\n",
    "#cw_amplitude means \"continuous-wave amplitude\"--i.e. the intensity\n",
    "#of the light being shone doesn't change\n",
    "fnirs_cw_amplitude_dir = op.join(fnirs_data_folder, 'Participant-1')\n",
    "\n",
    "\n",
    "#read in NIRX fNIRS recording with path to the data\n",
    "#documetation of Raw objects at https://mne.tools/stable/generated/mne.io.Raw.html#mne.io.Raw\n",
    "raw_intensity = mne.io.read_raw_nirx(fnirs_cw_amplitude_dir, verbose = True)\n",
    "\n",
    "#load raw data\n",
    "raw_intensity.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fc3597",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write data from NIRX file to snirf file for mne-nirs package\n",
    "write_raw_snirf(raw_intensity, 'test_raw.snirf')\n",
    "\n",
    "#read back the new snirf file\n",
    "snirf_intensity = read_raw_snirf('test_raw.snirf')\n",
    "\n",
    "#make sure the data from the original file and the SNIRF file\n",
    "#have the same values\n",
    "assert_allclose(raw_intensity.get_data(), snirf_intensity.get_data())\n",
    "snirf_intensity.plot(n_channels=30, duration=300, show_scrollbars=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82933a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# Validate SNIRF File\n",
    "# -------------------\n",
    "#\n",
    "# To validate that a file complies with the SNIRF standard you should use the\n",
    "# official SNIRF validator from the Boston University Neurophotonics Center\n",
    "# called ``pysnirf2``. Detailed instructions for this program can be found at\n",
    "# https://github.com/BUNPC/pysnirf2. Below we demonstrate that the files created\n",
    "# by MNE-NIRS are compliant with the specification.\n",
    "\n",
    "result = pysnirf2.validateSnirf('test_raw.snirf')\n",
    "assert result.is_valid()\n",
    "result.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4333dd",
   "metadata": {},
   "source": [
    "### now I have the NIRX format (raw intensity) and the snirf format data (snirf_intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b5162b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_intensity.plot(n_channels=30, duration=300, show_scrollbars=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3409d71",
   "metadata": {},
   "source": [
    "based on the description of the experiment, \"First, we attribute more meaningful names to the trigger codes which are stored as annotations. Second, we include information about the duration of each stimulus, which was 5 seconds for all conditions in this experiment. Third, we remove the trigger code 15, which signaled the start and end of the experiment and is not relevant to our analysis.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf34b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_intensity.annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f413225d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_intensity.describe()\n",
    "\n",
    "raw_intensity.annotations.set_durations(5)\n",
    "\n",
    "#C = control, TL = tapping left, and TR = tapping right\n",
    "raw_intensity.annotations.rename({'1.0': 'C',\n",
    "                                  '2.0': 'TL',\n",
    "                                  '3.0': 'TR'})\n",
    "\n",
    "#C = control, TL = tapping left, and TR = tapping right\n",
    "#raw_intensity.set_annotations(description = ['Start', 'C', 'TL', 'TR'])\n",
    "\n",
    "#.rename(1.0':'Control',\\\n",
    "#                                 '2.0':'Tapping/Left',\\\n",
    " #                                '3.0':'Tapping/Right'})\n",
    "\n",
    "unwanted = np.nonzero(raw_intensity.annotations.description == '15.0')\n",
    "raw_intensity.annotations.delete(unwanted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9805aed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_intensity.plot(n_channels=30, duration=300, show_scrollbars=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fd1625",
   "metadata": {},
   "outputs": [],
   "source": [
    "#important: finally how to get the channel names\n",
    "raw_intensity.ch_names\n",
    "\n",
    "#to get all data\n",
    "#raw_intensity._data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf63b7f",
   "metadata": {},
   "source": [
    "### Select good channels\n",
    "\n",
    "First we remove channels that are too close together (short channels) to detect a neural response (less than 1 cm distance between optodes). These short channels can be seen in the figure above. To achieve this we pick all the channels that are not considered to be short.\n",
    "\n",
    "**channels too close together aren't good**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378fd405",
   "metadata": {},
   "outputs": [],
   "source": [
    "#picks_types picks the channels by type and name.\n",
    "#here this picks all fnirs channels\n",
    "picks = mne.pick_types(raw_intensity.info, fnirs=True)\n",
    "\n",
    "#gives the distances between detectors\n",
    "dists = mne.preprocessing.nirs.source_detector_distances(\n",
    "    raw_intensity.info, picks=picks)\n",
    "\n",
    "#selects the channels with detectors creater than 1 cm apart\n",
    "raw_intensity.pick(picks[dists > 0.01])\n",
    "\n",
    "#plot\n",
    "raw_intensity.plot(n_channels=len(raw_intensity.ch_names),\n",
    "                   duration=500, show_scrollbars=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a175dcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to convert from \"raw intensity\" to \"optical density\",\n",
    "#remove negative values--change to their absolute values\n",
    "#and make sure all values are > 0\n",
    "\n",
    "raw_od = mne.preprocessing.nirs.optical_density(raw_intensity)\n",
    "\n",
    "#^the function is at https://github.com/mne-tools/mne-python/blob/maint/0.24/mne/preprocessing/nirs/_optical_density.py\n",
    "#It was harder to understand than I thought\n",
    "\n",
    "#^maybe figure out how to do this\n",
    "\n",
    "raw_od.plot(n_channels=len(raw_od.ch_names),\n",
    "            duration=500, show_scrollbars=False);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4ba051",
   "metadata": {},
   "source": [
    "# Now evaluate the data quality\n",
    "\n",
    "### 1) Visual Inspection\n",
    "\n",
    "Look for presence of physiological noise (heart rate) and motion artefacts (presence of baseline drift, baseline shift, and/or spike motion artefacts)\n",
    "\n",
    "\n",
    "\n",
    "info about processing the data before analyzing it from file:///C:/Users/taubm/Downloads/brainsci-11-00606.pdf:\n",
    "\n",
    "# Why use pre-processing and processing for raw fNIRS optical density data\n",
    "\n",
    "**HRF = hemodynamic response function**\n",
    "\n",
    "The primary goal of the pre-processing and processing of fNIRS data is to isolate\n",
    "the hemodynamic changes occurring in the vascular network of the gray matter. This is\n",
    "achieved by filtering raw data and estimating a HRF through modeling. These are referred\n",
    "to as pre-processing and processing, respectively. **In pre-processing, the objective is toremove extraneous noise from the raw data.** Noise can be classified as either **systematic**\n",
    "such as respiration, cardiac pulsation (heart rate), and changes in blood pressure. or **motion artefact (MA) noise** [9,22,23]. Noise removal techniques are applied prior to\n",
    "the HRF estimation. **Frequently used pre-processing techniques include frequency filters,\n",
    "wavelet, and smoothing filters.** Additionally, alternative methods such as **pre-whitening**\n",
    "can be used. Once the raw data has undergone pre-processing, methods are used to convert\n",
    "changes in light intensity to concentration changes in hemoglobin. **Processing is used to\n",
    "compare baseline and task-related hemodynamic changes [24].** These can be separated\n",
    "into either **general linear model (GLM) or non-GLM processing methods** such as block\n",
    "averaging and linear mixed models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c2d582",
   "metadata": {},
   "source": [
    "# So now I'm going to do pre-processing to remove noise\n",
    "\n",
    "\n",
    "## 1) first I'm going to look at systematic (regular & repeated) noise (e.g. heart rate, blood pressure, breathing)\n",
    "\n",
    "### Going to do low-pass, high-pass, and bandpass filtering\n",
    "\n",
    "**Note:** There are two general types of frequency filters for denoising: **infinite impulse response (IIR)** and\n",
    "**finite impulse response (FIR) filters.** The mathematical equations for these two types\n",
    "of filters differ in their filter coefficients, which are calculated as the ratio between the\n",
    "sampling frequency of the system and the cutoff frequency of the filter. FIR filters has filter coefficients that only depend on the data inputs to the filter. IIR filters depend on both the input data at each point & the previous outputs of the filter from all points before that.\n",
    "\n",
    "**Low-pass filter** get rid of or diminish frequencies above a certain value. This is used to get rid of high-frequency environmental noise like extra light, and physiological noise like cardiac pulsation and respiration.\n",
    "\n",
    "High-pass filters get rid of or diminish frequencies below a certain value. This is used to get rid of low frequency noise, mainly from baseline drift (gradual movement of the optode sensors along the scalp). **use scalp coupling index to analyze baseline drift**\n",
    "\n",
    "Band-pass filters get rid of/dimish frequencies outside of a specific range.\n",
    "\n",
    "These filters are used in fNIRS to attenuate high- and low-frequency physiological\n",
    "and instrumental noise.\n",
    "\n",
    "\n",
    "To find best range for band-pass filter, applying a fast Fourier transform (FFT) to an fNIRS dataset will allow the researcher to visually inspect the data and determine the spectral location of noises within a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2b1473",
   "metadata": {},
   "source": [
    "### Use scalp coupling index analysis to look for baseline drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd0eafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sci = mne.preprocessing.nirs.scalp_coupling_index(raw_od)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(sci)\n",
    "\n",
    "ax.set(xlabel = 'Scalp Coupling Index', ylabel = 'Count', xlim = [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf9c700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f54c9da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edd71a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba3dccd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
